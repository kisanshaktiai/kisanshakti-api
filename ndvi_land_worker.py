"""
NDVI Land Worker (v3.8-secure)
------------------------------
Processes queued NDVI requests for each tenant‚Äôs lands.

‚úÖ Enhancements (v3.8):
- RESTful endpoint naming conventions
- Consistent pluralized table and endpoint naming
- Versioned API path alignment (for integration consistency)
- Core logic untouched

¬© KisanShaktiAI | 2025
"""

import io
import os
import json
import datetime
import logging
import traceback
import base64
import requests
import numpy as np
import rasterio
from rasterio.mask import mask
from rasterio.io import MemoryFile
from rasterio.warp import transform_geom
from shapely.geometry import shape, mapping
from supabase import create_client

# ==========================
# CONFIGURATION
# ==========================
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
B2_KEY_ID = os.getenv("B2_KEY_ID")
B2_APP_KEY = os.getenv("B2_APP_KEY")
B2_BUCKET = os.getenv("B2_BUCKET")
B2_PREFIX = os.getenv("B2_PREFIX", "tiles/processed/")

if not SUPABASE_URL or not SUPABASE_KEY:
    raise ValueError("‚ùå Missing Supabase credentials (SUPABASE_URL or SUPABASE_SERVICE_ROLE_KEY)")

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger("ndvi-worker")

# ==========================
# B2 AUTHENTICATION
# ==========================
def get_b2_auth():
    """Authenticate securely with Backblaze B2 using key-based access."""
    if not all([B2_KEY_ID, B2_APP_KEY, B2_BUCKET]):
        raise ValueError("Missing one or more B2 credentials")

    credentials = base64.b64encode(f"{B2_KEY_ID}:{B2_APP_KEY}".encode()).decode()
    headers = {"Authorization": f"Basic {credentials}"}

    resp = requests.get("https://api.backblazeb2.com/b2api/v2/b2_authorize_account", headers=headers)
    if resp.status_code != 200:
        raise Exception(f"‚ùå B2 authorization failed: {resp.status_code} {resp.text[:200]}")

    data = resp.json()
    return {
        "api_url": data["apiUrl"],
        "download_url": data["downloadUrl"],
        "auth_token": data["authorizationToken"],
        "bucket_name": B2_BUCKET,
    }


def build_b2_path(tile_id: str, date: str, subdir: str, filename: str) -> str:
    """Construct object path based on prefix."""
    return f"{B2_PREFIX.rstrip('/')}/{subdir}/{tile_id}/{date}/{filename}"


def download_b2_file(tile_id: str, date: str, subdir: str, filename: str) -> io.BytesIO | None:
    """Securely download a file from Backblaze B2 bucket."""
    b2 = get_b2_auth()
    path = build_b2_path(tile_id, date, subdir, filename)
    url = f"{b2['download_url'].rstrip('/')}/file/{b2['bucket_name']}/{path}"

    headers = {"Authorization": b2["auth_token"]}
    logger.info(f"üì¶ Downloading from B2: {subdir}/{filename} for tile {tile_id}")

    try:
        resp = requests.get(url, headers=headers, timeout=90)
        if resp.status_code == 200:
            logger.info(f"‚úÖ {filename} ({len(resp.content)/1e6:.2f} MB) downloaded successfully")
            return io.BytesIO(resp.content)
        elif resp.status_code == 404:
            logger.warning(f"‚ö†Ô∏è File not found: {path}")
        else:
            logger.error(f"‚ùå B2 download failed ({resp.status_code}): {resp.text[:200]}")
    except Exception as e:
        logger.error(f"‚ùå Exception downloading from B2: {e}")

    return None


# ==========================
# NDVI CORE LOGIC
# ==========================
def calculate_ndvi(red: np.ndarray, nir: np.ndarray) -> np.ndarray:
    """Compute NDVI = (NIR - RED) / (NIR + RED)."""
    np.seterr(divide="ignore", invalid="ignore")
    denom = nir + red
    ndvi = np.where(denom == 0, np.nan, (nir - red) / denom)
    return np.clip(ndvi, -1, 1)


def calculate_statistics(arr: np.ndarray) -> dict:
    """Compute NDVI statistics."""
    valid = arr[~np.isnan(arr)]
    total = arr.size
    if valid.size == 0:
        return {
            "mean": None, "min": None, "max": None,
            "std": None, "valid_pixels": 0,
            "total_pixels": total, "coverage": 0.0,
        }
    return {
        "mean": float(np.mean(valid)),
        "min": float(np.min(valid)),
        "max": float(np.max(valid)),
        "std": float(np.std(valid)),
        "valid_pixels": int(valid.size),
        "total_pixels": int(total),
        "coverage": float(valid.size / total * 100),
    }


# ==========================
# PROCESSING FUNCTION
# ==========================
def process_farmer_land(land: dict, tile: dict) -> bool:
    """Process NDVI for a single land."""
    land_id = land["id"]
    tenant_id = land["tenant_id"]
    tile_id = tile["tile_id"]
    date = tile.get("acquisition_date") or datetime.date.today().isoformat()

    try:
        logger.info(f"üåø Processing land={land_id} | tile={tile_id}")

        geom_raw = land.get("boundary_polygon_old")
        if not geom_raw:
            raise Exception("Missing boundary_polygon_old")

        geom_json = json.loads(geom_raw) if isinstance(geom_raw, str) else geom_raw
        land_geom = shape(geom_json)

        # Prefer preprocessed NDVI file
        ndvi_buf = download_b2_file(tile_id, date, "ndvi", "ndvi.tif")
        if ndvi_buf:
            ndvi_src = rasterio.open(ndvi_buf)
            ndvi_arr = ndvi_src.read(1)
        else:
            b04_buf = download_b2_file(tile_id, date, "raw", "B04.tif")
            b08_buf = download_b2_file(tile_id, date, "raw", "B08.tif")
            if not b04_buf or not b08_buf:
                raise Exception("Missing Sentinel bands or NDVI file in B2")
            with rasterio.open(b04_buf) as red_src, rasterio.open(b08_buf) as nir_src:
                geom_trans = transform_geom("EPSG:4326", red_src.crs.to_string(), mapping(land_geom))
                red_clip, _ = mask(red_src, [geom_trans], crop=True, nodata=np.nan)
                nir_clip, _ = mask(nir_src, [geom_trans], crop=True, nodata=np.nan)
                ndvi_arr = calculate_ndvi(red_clip[0].astype(float), nir_clip[0].astype(float))

        stats = calculate_statistics(ndvi_arr)
        if stats["valid_pixels"] == 0:
            raise Exception("No valid NDVI pixels found")

        ndvi_record = {
            "tenant_id": tenant_id,
            "land_id": land_id,
            "tile_id": tile_id,
            "date": date,
            "ndvi_value": stats["mean"],
            "ndvi_min": stats["min"],
            "ndvi_max": stats["max"],
            "ndvi_std": stats["std"],
            "coverage": stats["coverage"],
            "created_at": datetime.datetime.utcnow().isoformat(),
            "metadata": stats,
        }

        supabase.table("ndvi_data").upsert(ndvi_record, on_conflict="land_id,date").execute()
        supabase.table("lands").update({
            "last_ndvi_value": stats["mean"],
            "last_ndvi_calculation": date,
        }).eq("id", land_id).execute()

        logger.info(f"‚úÖ NDVI saved for land {land_id} | mean={stats['mean']:.3f}")
        return True

    except Exception as e:
        tb = traceback.format_exc()
        logger.error(f"‚ùå Land processing failed: {e}\n{tb[:400]}")
        supabase.table("ndvi_processing_logs").insert({
            "tenant_id": tenant_id,
            "land_id": land_id,
            "satellite_tile_id": tile.get("id"),
            "processing_step": "ndvi_calculation",
            "step_status": "failed",
            "completed_at": datetime.datetime.utcnow().isoformat(),
            "error_message": str(e),
            "error_details": {"traceback": tb[:400]},
            "metadata": {"tile_id": tile_id, "date": date},
        }).execute()
        return False


# ==========================
# QUEUE PROCESSOR
# ==========================
def process_queue(limit: int = 10):
    """Process queued NDVI requests."""
    logger.info("üßæ Checking NDVI request queue...")
    rq = supabase.table("ndvi_request_queue").select("*").eq("status", "queued").limit(limit).execute()
    requests = rq.data or []
    if not requests:
        logger.info("‚úÖ No queued NDVI requests.")
        return

    for req in requests:
        req_id = req["id"]
        tenant_id = req["tenant_id"]
        tile_id = req["tile_id"]
        logger.info(f"‚öôÔ∏è Processing queue {req_id} for tenant={tenant_id} tile={tile_id}")

        supabase.table("ndvi_request_queue").update({
            "status": "processing",
            "started_at": datetime.datetime.utcnow().isoformat(),
        }).eq("id", req_id).execute()

        lands = supabase.table("lands").select("*").eq("tenant_id", tenant_id).in_("id", req["land_ids"]).execute().data
        if not lands:
            supabase.table("ndvi_request_queue").update({
                "status": "failed",
                "error_message": "No lands found",
            }).eq("id", req_id).execute()
            continue

        tile_res = supabase.table("satellite_tiles").select("*").eq("tile_id", tile_id).limit(1).execute()
        if not tile_res.data:
            supabase.table("ndvi_request_queue").update({
                "status": "failed",
                "error_message": "Missing tile metadata",
            }).eq("id", req_id).execute()
            continue

        tile = tile_res.data[0]
        processed = sum(process_farmer_land(land, tile) for land in lands)

        supabase.table("ndvi_request_queue").update({
            "status": "completed",
            "processed_count": processed,
            "completed_at": datetime.datetime.utcnow().isoformat(),
        }).eq("id", req_id).execute()

        logger.info(f"üéØ Completed request {req_id} | Lands processed: {processed}")


# ==========================
# ENTRY POINT
# ==========================
def main(limit: int = 10):
    logger.info("üöÄ NDVI Worker started (v3.8-secure)")
    process_queue(limit)
    logger.info("üèÅ NDVI Worker finished.")


if __name__ == "__main__":
    main()
